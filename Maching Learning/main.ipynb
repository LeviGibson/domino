{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-04 11:56:26.886885: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-09-04 11:56:26.886922: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = []\n",
    "# y = []\n",
    "\n",
    "# infile = open(\"dataset.csv\", 'r')\n",
    "# for line in infile:\n",
    "#     line = line.split(',')\n",
    "#     print(line)\n",
    "\n",
    "x = pd.read_csv(\"dataset.csv\", low_memory=True)\n",
    "x.pop(x.columns[-1])\n",
    "y = x.pop(\"label\")\n",
    "# y = x.pop(\"blocks\")\n",
    "x = x.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "# x = np.zeros(dtype=bool, shape=(int(5000000/1000), 1000, 3))\n",
    "# print(\"done\")\n",
    "# y = []\n",
    "# for id, xp in enumerate(pd.read_csv(\"dataset.csv\", chunksize=1000)):\n",
    "#     xp.pop(xp.columns[-1])\n",
    "#     yp = xp.pop(\"label\")\n",
    "#     x[id] = xp.to_numpy().astype(bool)\n",
    "#     y.append(yp.to_numpy())\n",
    "\n",
    "# y = to_categorical(y, num_classes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-04 11:56:31.524858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-04 11:56:31.525458: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-09-04 11:56:31.525528: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-09-04 11:56:31.525562: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-09-04 11:56:31.525594: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-09-04 11:56:31.525624: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-09-04 11:56:31.525654: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-09-04 11:56:31.525684: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-09-04 11:56:31.525715: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-09-04 11:56:31.525721: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-09-04 11:56:31.526604: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(x.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-04 11:56:33.648455: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 179200000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6250/6250 [==============================] - 17s 3ms/step - loss: 1.2252 - mae: 0.7608 - val_loss: 0.8173 - val_mae: 0.7127\n",
      "Epoch 2/10\n",
      "6250/6250 [==============================] - 16s 3ms/step - loss: 0.8282 - mae: 0.7170 - val_loss: 0.8050 - val_mae: 0.7078\n",
      "Epoch 3/10\n",
      "6250/6250 [==============================] - 16s 3ms/step - loss: 0.8193 - mae: 0.7134 - val_loss: 0.8039 - val_mae: 0.7083\n",
      "Epoch 4/10\n",
      "6250/6250 [==============================] - 16s 3ms/step - loss: 0.8169 - mae: 0.7123 - val_loss: 0.8178 - val_mae: 0.7109\n",
      "Epoch 5/10\n",
      "6250/6250 [==============================] - 16s 3ms/step - loss: 0.8157 - mae: 0.7119 - val_loss: 0.8197 - val_mae: 0.7175\n",
      "Epoch 6/10\n",
      "3746/6250 [================>.............] - ETA: 5s - loss: 0.8123 - mae: 0.7106"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/levigibson/Pictures/programming/C++/domino/Maching Learning/main.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/levigibson/Pictures/programming/C%2B%2B/domino/Maching%20Learning/main.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/levigibson/Pictures/programming/C%2B%2B/domino/Maching%20Learning/main.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(x, y, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/levigibson/Pictures/programming/C%2B%2B/domino/Maching%20Learning/main.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/levigibson/Pictures/programming/C%2B%2B/domino/Maching%20Learning/main.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mEpoch 1/10\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/levigibson/Pictures/programming/C%2B%2B/domino/Maching%20Learning/main.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m6250/6250 [==============================] - 15s 2ms/step - loss: 1.6504 - mae: 0.8080 - val_loss: 0.8536 - val_mae: 0.7261\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/levigibson/Pictures/programming/C%2B%2B/domino/Maching%20Learning/main.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/levigibson/Pictures/programming/C%2B%2B/domino/Maching%20Learning/main.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:1389\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs  \u001b[39m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1388\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1389\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1391\u001b[0m   \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \n\u001b[1;32m    433\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 438\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m'\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m'\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    296\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mend\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 297\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    300\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. Expected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m   batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 318\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    320\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    321\u001b[0m   end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    355\u001b[0m   hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 356\u001b[0m   hook(batch, logs)\n\u001b[1;32m    358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    359\u001b[0m   \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1034\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/callbacks.py:1106\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[1;32m   1104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1105\u001b[0m   \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1106\u001b[0m   logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   1107\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/tf_utils.py:563\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m    561\u001b[0m   \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[0;32m--> 563\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:911\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    907\u001b[0m   assert_same_structure(structure[\u001b[39m0\u001b[39m], other, check_types\u001b[39m=\u001b[39mcheck_types,\n\u001b[1;32m    908\u001b[0m                         expand_composites\u001b[39m=\u001b[39mexpand_composites)\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m--> 911\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39;49m(\u001b[39m*\u001b[39;49mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m    914\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:910\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[39mfor\u001b[39;00m other \u001b[39min\u001b[39;00m structure[\u001b[39m1\u001b[39m:]:\n\u001b[1;32m    907\u001b[0m   assert_same_structure(structure[\u001b[39m0\u001b[39m], other, check_types\u001b[39m=\u001b[39mcheck_types,\n\u001b[1;32m    908\u001b[0m                         expand_composites\u001b[39m=\u001b[39mexpand_composites)\n\u001b[0;32m--> 910\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m    914\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:451\u001b[0m, in \u001b[0;36mflatten\u001b[0;34m(structure, expand_composites)\u001b[0m\n\u001b[1;32m    449\u001b[0m   \u001b[39mreturn\u001b[39;00m [\u001b[39mNone\u001b[39;00m]\n\u001b[1;32m    450\u001b[0m expand_composites \u001b[39m=\u001b[39m \u001b[39mbool\u001b[39m(expand_composites)\n\u001b[0;32m--> 451\u001b[0m \u001b[39mreturn\u001b[39;00m _pywrap_utils\u001b[39m.\u001b[39;49mFlatten(structure, expand_composites)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "model.fit(x, y, batch_size=64, epochs=10, validation_split=0.2)\n",
    "\n",
    "\"\"\"\n",
    "Epoch 1/10\n",
    "6250/6250 [==============================] - 15s 2ms/step - loss: 1.6504 - mae: 0.8080 - val_loss: 0.8536 - val_mae: 0.7261\n",
    "Epoch 2/10\n",
    "6250/6250 [==============================] - 15s 2ms/step - loss: 0.8571 - mae: 0.7306 - val_loss: 0.8430 - val_mae: 0.7237\n",
    "Epoch 3/10\n",
    "6250/6250 [==============================] - 14s 2ms/step - loss: 0.8500 - mae: 0.7273 - val_loss: 0.8382 - val_mae: 0.7246\n",
    "Epoch 4/10\n",
    "6250/6250 [==============================] - 15s 2ms/step - loss: 0.8448 - mae: 0.7257 - val_loss: 0.8461 - val_mae: 0.7210\n",
    "Epoch 5/10\n",
    "6250/6250 [==============================] - 15s 2ms/step - loss: 0.8425 - mae: 0.7246 - val_loss: 0.8368 - val_mae: 0.7245\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#5516/5516 [==============================] - 15s 3ms/step - loss: 8.9091 - accuracy: 0.1406 - val_loss: 8.9105 - val_accuracy: 0.1390"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
