{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = []\n",
    "# y = []\n",
    "\n",
    "# infile = open(\"dataset.csv\", 'r')\n",
    "# for line in infile:\n",
    "#     line = line.split(',')\n",
    "#     print(line)\n",
    "\n",
    "x = pd.read_csv(\"dataset.csv\", low_memory=True)\n",
    "x.pop(x.columns[-1])\n",
    "y = x.pop(\"label\")\n",
    "x = x.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "# x = np.zeros(dtype=bool, shape=(int(5000000/1000), 1000, 3))\n",
    "# print(\"done\")\n",
    "# y = []\n",
    "# for id, xp in enumerate(pd.read_csv(\"dataset.csv\", chunksize=1000)):\n",
    "#     xp.pop(xp.columns[-1])\n",
    "#     yp = xp.pop(\"label\")\n",
    "#     x[id] = xp.to_numpy().astype(bool)\n",
    "#     y.append(yp.to_numpy())\n",
    "\n",
    "# # y = to_categorical(y, num_classes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(x.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6250/6250 [==============================] - 19s 3ms/step - loss: 2.2306 - mae: 1.0595 - val_loss: 1.5364 - val_mae: 0.9865\n",
      "Epoch 2/10\n",
      "6250/6250 [==============================] - 17s 3ms/step - loss: 1.5701 - mae: 0.9960 - val_loss: 1.5442 - val_mae: 1.0088\n",
      "Epoch 3/10\n",
      "6250/6250 [==============================] - 18s 3ms/step - loss: 1.5663 - mae: 0.9965 - val_loss: 1.5353 - val_mae: 0.9890\n",
      "Epoch 4/10\n",
      "6250/6250 [==============================] - 17s 3ms/step - loss: 1.5676 - mae: 0.9963 - val_loss: 1.5504 - val_mae: 1.0132\n",
      "Epoch 5/10\n",
      "6250/6250 [==============================] - 16s 3ms/step - loss: 1.5669 - mae: 0.9963 - val_loss: 1.5753 - val_mae: 0.9613\n",
      "Epoch 6/10\n",
      "6250/6250 [==============================] - 16s 3ms/step - loss: 1.5650 - mae: 0.9959 - val_loss: 1.5822 - val_mae: 1.0279\n",
      "Epoch 7/10\n",
      "6250/6250 [==============================] - 16s 3ms/step - loss: 1.5646 - mae: 0.9959 - val_loss: 1.5472 - val_mae: 0.9755\n",
      "Epoch 8/10\n",
      "2304/6250 [==========>...................] - ETA: 8s - loss: 1.5641 - mae: 0.9971"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/levigibson/Pictures/programming/C++/domino/Maching Learning/main.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/levigibson/Pictures/programming/C%2B%2B/domino/Maching%20Learning/main.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/levigibson/Pictures/programming/C%2B%2B/domino/Maching%20Learning/main.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(x, y, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/levigibson/Pictures/programming/C%2B%2B/domino/Maching%20Learning/main.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/levigibson/Pictures/programming/C%2B%2B/domino/Maching%20Learning/main.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mEpoch 1/10\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/levigibson/Pictures/programming/C%2B%2B/domino/Maching%20Learning/main.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m6250/6250 [==============================] - 20s 3ms/step - loss: 1.6577 - mae: 0.9480 - val_loss: 1.1347 - val_mae: 0.8426\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/levigibson/Pictures/programming/C%2B%2B/domino/Maching%20Learning/main.ipynb#W4sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m6250/6250 [==============================] - 26s 4ms/step - loss: 0.8851 - mae: 0.7380 - val_loss: 0.9042 - val_mae: 0.7423\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/levigibson/Pictures/programming/C%2B%2B/domino/Maching%20Learning/main.ipynb#W4sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1385\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:909\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    904\u001b[0m   \u001b[39mif\u001b[39;00m ops\u001b[39m.\u001b[39mexecuting_eagerly_outside_functions() \u001b[39mand\u001b[39;00m (\n\u001b[1;32m    905\u001b[0m       context\u001b[39m.\u001b[39mexecuting_eagerly() \u001b[39mor\u001b[39;00m compiled):\n\u001b[1;32m    906\u001b[0m     \u001b[39m# Labels must be strings in Python, so we convert 'compiled' to a string\u001b[39;00m\n\u001b[1;32m    907\u001b[0m     _tf_function_counter\u001b[39m.\u001b[39mget_cell(\u001b[39mstr\u001b[39m(\u001b[39mint\u001b[39m(compiled)))\u001b[39m.\u001b[39mincrease_by(\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 909\u001b[0m tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexperimental_get_tracing_count()\n\u001b[1;32m    910\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name) \u001b[39mas\u001b[39;00m tm:\n\u001b[1;32m    911\u001b[0m   \u001b[39m# TODO(cheshire): Do not duplicate the XLAControlFlowContext annotation.\u001b[39;00m\n\u001b[1;32m    912\u001b[0m   compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:880\u001b[0m, in \u001b[0;36mFunction.experimental_get_tracing_count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39m\"\"\"Returns the number of times the function has been traced.\u001b[39;00m\n\u001b[1;32m    852\u001b[0m \n\u001b[1;32m    853\u001b[0m \u001b[39mFor more information on when a function is traced and when it is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    877\u001b[0m \n\u001b[1;32m    878\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    879\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn\u001b[39m.\u001b[39mtracing_count \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 880\u001b[0m result \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39mtracing_count \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m    881\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "model.fit(x, y, batch_size=64, epochs=10, validation_split=0.2)\n",
    "\n",
    "\"\"\"\n",
    "Epoch 1/10\n",
    "6250/6250 [==============================] - 20s 3ms/step - loss: 1.6577 - mae: 0.9480 - val_loss: 1.1347 - val_mae: 0.8426\n",
    "Epoch 2/10\n",
    "6250/6250 [==============================] - 19s 3ms/step - loss: 1.0715 - mae: 0.8120 - val_loss: 1.0228 - val_mae: 0.8033\n",
    "Epoch 3/10\n",
    "6250/6250 [==============================] - 19s 3ms/step - loss: 1.0088 - mae: 0.7885 - val_loss: 0.9747 - val_mae: 0.7757\n",
    "Epoch 4/10\n",
    "6250/6250 [==============================] - 21s 3ms/step - loss: 0.9759 - mae: 0.7751 - val_loss: 0.9625 - val_mae: 0.7623\n",
    "Epoch 5/10\n",
    "6250/6250 [==============================] - 26s 4ms/step - loss: 0.9530 - mae: 0.7660 - val_loss: 1.0108 - val_mae: 0.8095\n",
    "Epoch 6/10\n",
    "6250/6250 [==============================] - 26s 4ms/step - loss: 0.9331 - mae: 0.7578 - val_loss: 0.9281 - val_mae: 0.7515\n",
    "Epoch 7/10\n",
    "6250/6250 [==============================] - 25s 4ms/step - loss: 0.9178 - mae: 0.7518 - val_loss: 0.9259 - val_mae: 0.7475\n",
    "Epoch 8/10\n",
    "6250/6250 [==============================] - 26s 4ms/step - loss: 0.9043 - mae: 0.7459 - val_loss: 0.9088 - val_mae: 0.7468\n",
    "Epoch 9/10\n",
    "6250/6250 [==============================] - 26s 4ms/step - loss: 0.8938 - mae: 0.7419 - val_loss: 0.9188 - val_mae: 0.7603\n",
    "Epoch 10/10\n",
    "6250/6250 [==============================] - 26s 4ms/step - loss: 0.8851 - mae: 0.7380 - val_loss: 0.9042 - val_mae: 0.7423\n",
    "\"\"\"\n",
    "\n",
    "#5516/5516 [==============================] - 15s 3ms/step - loss: 8.9091 - accuracy: 0.1406 - val_loss: 8.9105 - val_accuracy: 0.1390"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
